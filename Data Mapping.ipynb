{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "import re\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths for input and output\n",
    "input_dir = 'C:\\\\Users\\\\DELL\\\\Downloads\\\\entry'\n",
    "output_dir = 'C:\\\\Users\\\\DELL\\\\Downloads\\\\final'\n",
    "\n",
    "# Name of the input file\n",
    "file_entry_name = 'example_1.sql'\n",
    "\n",
    "# Name of the desired output file\n",
    "file_output_name = 'example_final.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete paths for the files\n",
    "input_file_path = os.path.join(input_dir, file_entry_name)\n",
    "output_file_path = os.path.join(output_dir, file_output_name)\n",
    "\n",
    "# Check if the input file exists\n",
    "if not os.path.exists(input_file_path):\n",
    "    print(f\"Error: Input file {input_file_path} not found.\")\n",
    "else:\n",
    "    # Read the SQL file\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        sql_query = file.read()\n",
    "\n",
    "    # Split the query into parts based on SELECT statements\n",
    "    select_sections = re.split(r'\\bSELECT\\b', sql_query, flags=re.IGNORECASE)\n",
    "\n",
    "    # Patterns to match the required tables and fields\n",
    "    pattern_tables = r'\\b(FROM|JOIN|INNER JOIN|LEFT JOIN|RIGHT JOIN|FULL JOIN)\\s+(MARKETINGOPERATIONS\\.DM_CORE\\.[\\w\\.]+|prod_datalake\\.sfdc\\.[\\w\\.]+|experience_index_db\\.xi_operations_dev\\.[\\w\\.]+|(?:\\(\\s*SELECT[^)]+\\)))(?:\\s+AS\\s+(\\w+)|\\s+(\\w+))?'\n",
    "    pattern_fields = r'(\\w+)\\.(\\w+)(?:\\s+AS\\s+(\\w+))?'\n",
    "    pattern_calculations = r'(SUM|COUNT|AVG|MIN|MAX|LOWER|UPPER|COALESCE|CASE|ROUND|CAST|CONCAT|SUBSTRING|REPLACE|DATEADD|DATEDIFF|ISNULL)\\s*\\(.*?\\)'\n",
    "\n",
    "    # Lists to store the extracted data\n",
    "    table_data = []\n",
    "    field_data = []\n",
    "\n",
    "    # Process each select section\n",
    "    for index, section in enumerate(select_sections):\n",
    "        if not section.strip():\n",
    "            continue\n",
    "\n",
    "        # Find all table matches in the section\n",
    "        table_matches = re.findall(pattern_tables, section, re.IGNORECASE)\n",
    "        for match in table_matches:\n",
    "            relationship = match[0]\n",
    "            table_name = match[1]\n",
    "            alias = match[2] if match[2] and match[2].lower() not in [\"where\", \"group\", \"order\", \"by\", \"limit\", \"having\"] else match[3] if match[3] and match[3].lower() not in [\"where\", \"group\", \"order\", \"by\", \"limit\", \"having\"] else ''\n",
    "            table_data.append([f'SELECT {index + 1}', relationship, table_name, alias])\n",
    "\n",
    "        # Find all field matches in the section\n",
    "        field_matches = re.findall(pattern_fields, section, re.IGNORECASE)\n",
    "        for match in field_matches:\n",
    "            field_with_alias = f\"{match[0]}.{match[1]} AS {match[2]}\" if match[2] else f\"{match[0]}.{match[1]}\"\n",
    "            calculation = ''\n",
    "            if re.search(pattern_calculations, field_with_alias, re.IGNORECASE):\n",
    "                calculation = re.search(pattern_calculations, field_with_alias, re.IGNORECASE).group(1)\n",
    "            field_data.append([field_with_alias, match[0], match[1], match[2] if match[2] else '', 'YES' if calculation else 'NO', calculation])\n",
    "\n",
    "    # Create DataFrames from the collected data\n",
    "    df_tables = pd.DataFrame(table_data, columns=['Select Part', 'Relationship', 'Table Name', 'Alias']).drop_duplicates()\n",
    "    df_fields = pd.DataFrame(field_data, columns=['Field', 'Prefix', 'Raw Field', 'Alias', 'Calculated', 'Calculation']).drop_duplicates()\n",
    "\n",
    "    # Fill missing aliases in the tables\n",
    "    df_tables['Alias'] = df_tables.apply(lambda row: row['Table Name'].split('.')[-1] if row['Alias'] == '' else row['Alias'], axis=1)\n",
    "\n",
    "    # Count occurrences of SELECT, fields, tables, WHERE, and calculated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
