{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "# Iniciar sessão Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DatabricksSalesExample\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Conectar ao banco de dados\n",
    "jdbc_url = \"jdbc:spark://your_spark_server:443/default;transportMode=http;ssl=1;httpPath=/sql/1.0/endpoints/your_endpoint\"\n",
    "connection_properties = {\n",
    "    \"user\": \"your_username\",\n",
    "    \"password\": \"your_password\",\n",
    "    \"driver\": \"org.apache.hive.jdbc.HiveDriver\"\n",
    "}\n",
    "\n",
    "# Executar consulta\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    order_id AS \"Order ID\",\n",
    "    order_date AS \"Order Date\",\n",
    "    customer_id AS \"Customer ID\",\n",
    "    product_id AS \"Product ID\",\n",
    "    quantity AS \"Quantity\",\n",
    "    unit_price AS \"Unit Price\",\n",
    "    total_price AS \"Total Price\"\n",
    "FROM\n",
    "    sales_orders\n",
    "\"\"\"\n",
    "\n",
    "# Obter resultados da consulta\n",
    "df = spark.read.jdbc(url=jdbc_url, table=f\"({query}) as temp\", properties=connection_properties)\n",
    "\n",
    "# Converter para Pandas DataFrame\n",
    "pdf = df.toPandas()\n",
    "\n",
    "# Exibir os primeiros registros do DataFrame\n",
    "print(pdf.head())\n",
    "\n",
    "# Fechar sessão Spark\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
